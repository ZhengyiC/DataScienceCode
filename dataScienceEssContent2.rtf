{\rtf1\ansi\ansicpg1252\cocoartf1671\cocoasubrtf600
{\fonttbl\f0\fswiss\fcharset0 Helvetica;}
{\colortbl;\red255\green255\blue255;\red252\green118\blue111;\red230\green87\blue141;\red252\green73\blue64;
}
{\*\expandedcolortbl;;\cssrgb\c100000\c55025\c50890;\cssrgb\c93000\c44193\c62103;\cssrgb\c100000\c38374\c31601;
}
\margl1440\margr1440\vieww10800\viewh8400\viewkind0
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural\partightenfactor0

\f0\fs28 \cf0 Ch01-02 Introduction\
	see Ch1_intro ipynb \
		terminologies, important methods and steps to find algorithm \
\
Ch03\
\
	3_1: simple variable linear regression \
		some usage of bumpy \cf2 random (ransom.rand, randn, randint)\cf0 \
		create sklearn\'92s \cf2 LinearRegression()\cf0  instance \
		its \cf3 fit(x,y)\cf0  and\cf3  score(x,y\cf0 ) function \
		its \cf3 intercept_ and coef_\cf0  field \
\
	3_2 multi-variant linear regression:\
		using sea born to check relation between variables and the potential predictant \
			use \cf2 sb.pairplot( pd\'92s DF obj)\cf0 \
		\cf4 scale( X)\cf0  to standardize \
		checking missing values\
		use \cf2 normalization\cf0  in the linear regression model \
		check how well the model fits \cf4 ( model.score(X,y) ) \cf0  }